{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       age     workclass   fnlgt  education  education-num  \\\n18124   32       Private  328060        9th              5   \n25799   46   Federal-gov  344415    Masters             14   \n23893   43       Private   91949    HS-grad              9   \n21950   34  Self-emp-inc  209538  Bachelors             13   \n21195   55       Private  196126  Bachelors             13   \n\n           marital-status         occupation   relationship   race     sex  \\\n18124           Separated      Other-service      Unmarried  Other  Female   \n25799  Married-civ-spouse       Armed-Forces        Husband  White    Male   \n23893            Divorced  Machine-op-inspct  Not-in-family  Black  Female   \n21950  Married-civ-spouse              Sales        Husband  White    Male   \n21195           Separated       Craft-repair  Not-in-family  White    Male   \n\n       capital-gain  capital-loss  hours-per-week native-country salary  \n18124             0             0              40         Mexico  <=50K  \n25799             0          1887              40  United-States   >50K  \n23893             0             0              40  United-States  <=50K  \n21950             0             0              50  United-States   >50K  \n21195             0             0              40              ?  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18124</th>\n      <td>32</td>\n      <td>Private</td>\n      <td>328060</td>\n      <td>9th</td>\n      <td>5</td>\n      <td>Separated</td>\n      <td>Other-service</td>\n      <td>Unmarried</td>\n      <td>Other</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Mexico</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>25799</th>\n      <td>46</td>\n      <td>Federal-gov</td>\n      <td>344415</td>\n      <td>Masters</td>\n      <td>14</td>\n      <td>Married-civ-spouse</td>\n      <td>Armed-Forces</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>1887</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>23893</th>\n      <td>43</td>\n      <td>Private</td>\n      <td>91949</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Machine-op-inspct</td>\n      <td>Not-in-family</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>21950</th>\n      <td>34</td>\n      <td>Self-emp-inc</td>\n      <td>209538</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Sales</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>21195</th>\n      <td>55</td>\n      <td>Private</td>\n      <td>196126</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Separated</td>\n      <td>Craft-repair</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>?</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./../data/census.csv\", skipinitialspace = True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data.rename(columns={\n",
    "    \"education-num\": \"education_num\",\n",
    "    \"marital-status\": \"marital_status\",\n",
    "    \"hours-per-week\": \"hours_per_week\",\n",
    "    \"native-country\": \"native_country\"\n",
    "}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       age         workclass   fnlgt   education  education_num  \\\n0       39         State-gov   77516   Bachelors             13   \n1       50  Self-emp-not-inc   83311   Bachelors             13   \n2       38           Private  215646     HS-grad              9   \n3       53           Private  234721        11th              7   \n4       28           Private  338409   Bachelors             13   \n...    ...               ...     ...         ...            ...   \n32556   27           Private  257302  Assoc-acdm             12   \n32557   40           Private  154374     HS-grad              9   \n32558   58           Private  151910     HS-grad              9   \n32559   22           Private  201490     HS-grad              9   \n32560   52      Self-emp-inc  287927     HS-grad              9   \n\n           marital_status         occupation   relationship   race     sex  \\\n0           Never-married       Adm-clerical  Not-in-family  White    Male   \n1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n...                   ...                ...            ...    ...     ...   \n32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n32558             Widowed       Adm-clerical      Unmarried  White  Female   \n32559       Never-married       Adm-clerical      Own-child  White    Male   \n32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n\n       capital-gain  capital-loss  hours_per_week native_country salary  \n0              2174             0              40  United-States  <=50K  \n1                 0             0              13  United-States  <=50K  \n2                 0             0              40  United-States  <=50K  \n3                 0             0              40  United-States  <=50K  \n4                 0             0              40           Cuba  <=50K  \n...             ...           ...             ...            ...    ...  \n32556             0             0              38  United-States  <=50K  \n32557             0             0              40  United-States   >50K  \n32558             0             0              40  United-States  <=50K  \n32559             0             0              20  United-States  <=50K  \n32560         15024             0              40  United-States   >50K  \n\n[32561 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlgt</th>\n      <th>education</th>\n      <th>education_num</th>\n      <th>marital_status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours_per_week</th>\n      <th>native_country</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32556</th>\n      <td>27</td>\n      <td>Private</td>\n      <td>257302</td>\n      <td>Assoc-acdm</td>\n      <td>12</td>\n      <td>Married-civ-spouse</td>\n      <td>Tech-support</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32557</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>154374</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>32558</th>\n      <td>58</td>\n      <td>Private</td>\n      <td>151910</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Widowed</td>\n      <td>Adm-clerical</td>\n      <td>Unmarried</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32559</th>\n      <td>22</td>\n      <td>Private</td>\n      <td>201490</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32560</th>\n      <td>52</td>\n      <td>Self-emp-inc</td>\n      <td>287927</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>15024</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n<p>32561 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `Removing Extra Whitespace from Whole DataFrame by Creating some code :`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "######## Importing required libraries\n",
    "\n",
    "######## Creating DataFrame having 4 columns and but\n",
    "######## the data is in unregularized way.\n",
    "\n",
    "def whitespace_remover(dataframe):\n",
    "   \n",
    "    ######## iterating over the columns\n",
    "    for i in dataframe.columns:\n",
    "         \n",
    "        ######## checking datatype of each columns\n",
    "        if dataframe[i].dtype == 'object':\n",
    "             \n",
    "            ######## applying strip function on column\n",
    "            dataframe[i] = dataframe[i].map(str.strip)\n",
    "        else:\n",
    "             \n",
    "            ######## if condn. is False then it will do nothing.\n",
    "            pass\n",
    " \n",
    "######## applying whitespace_remover function on dataframe\n",
    "whitespace_remover(df)\n",
    " \n",
    "######## printing dataframe\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating ydata_profiling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(data, title=\"Pandas Profiling Report\")\n",
    "profile.to_widgets()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def process_data(\n",
    "    X, categorical_features=[], label=None, training=True, encoder=None, lb=None\n",
    "):\n",
    "    \"\"\" Process the data used in the machine learning pipeline.\n",
    "\n",
    "    Processes the data using one hot encoding for the categorical features and a\n",
    "    label binarizer for the labels. This can be used in either training or\n",
    "    inference/validation.\n",
    "\n",
    "    Note: depending on the type of model used, you may want to add in functionality that\n",
    "    scales the continuous data.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    X : pd.DataFrame\n",
    "        Dataframe containing the features and label. Columns in `categorical_features`\n",
    "    categorical_features: list[str]\n",
    "        List containing the names of the categorical features (default=[])\n",
    "    label : str\n",
    "        Name of the label column in `X`. If None, then an empty array will be returned\n",
    "        for y (default=None)\n",
    "    training : bool\n",
    "        Indicator if training mode or inference/validation mode.\n",
    "    encoder : sklearn.preprocessing._encoders.OneHotEncoder\n",
    "        Trained sklearn OneHotEncoder, only used if training=False.\n",
    "    lb : sklearn.preprocessing._label.LabelBinarizer\n",
    "        Trained sklearn LabelBinarizer, only used if training=False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        Processed data.\n",
    "    y : np.array\n",
    "        Processed labels if labeled=True, otherwise empty np.array.\n",
    "    encoder : sklearn.preprocessing._encoders.OneHotEncoder\n",
    "        Trained OneHotEncoder if training is True, otherwise returns the encoder passed\n",
    "        in.\n",
    "    lb : sklearn.preprocessing._label.LabelBinarizer\n",
    "        Trained LabelBinarizer if training is True, otherwise returns the binarizer\n",
    "        passed in.\n",
    "    \"\"\"\n",
    "\n",
    "    if label is not None:\n",
    "        y = X[label]\n",
    "        X = X.drop([label], axis=1)\n",
    "    else:\n",
    "        y = np.array([])\n",
    "\n",
    "    X_categorical = X[categorical_features].values\n",
    "    X_continuous = X.drop(categorical_features, axis=1)\n",
    "\n",
    "    if training is True:\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "        lb = LabelBinarizer()\n",
    "        X_categorical = encoder.fit_transform(X_categorical)\n",
    "        y = lb.fit_transform(y.values).ravel()\n",
    "    else:\n",
    "        if encoder is None or lb is None:\n",
    "            raise ValueError(\"Encoder and LabelBinarizer must be provided in training=False mode.\")\n",
    "        X_categorical = encoder.transform(X_categorical)\n",
    "        try:\n",
    "            y = lb.transform(y.values).ravel()\n",
    "        # Catch the case where y is None because we're doing inference.\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    X = np.concatenate([X_continuous, X_categorical], axis=1)\n",
    "    return X, y, encoder, lb\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Predict Test Data \n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate accuracy, precision, recall, f1-score, and kappa score\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    prec = metrics.precision_score(y_test, y_pred)\n",
    "    rec = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate area under curve (AUC)\n",
    "    y_pred_proba = model.predict_proba(x_test)[::,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Display confussion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'kappa': kappa, \n",
    "            'fpr': fpr, 'tpr': tpr, 'auc': auc, 'cm': cm}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training + Prediction + Model Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a machine learning model and returns it.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    X_train : np.array\n",
    "        Training data.\n",
    "    y_train : np.array\n",
    "        Labels.\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        Trained machine learning model.\n",
    "    \"\"\"\n",
    "\n",
    "    clf_model = DecisionTreeClassifier(random_state=42)\n",
    "    return clf_model.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "def inference(model, X):\n",
    "    \"\"\" Run model inferences and return the predictions.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    model : ???\n",
    "        Trained machine learning model.\n",
    "    X : np.array\n",
    "        Data used for prediction.\n",
    "    Returns\n",
    "    -------\n",
    "    preds : np.array\n",
    "        Predictions from the model.\n",
    "    \"\"\"\n",
    "    return model.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "def compute_model_metrics(y, preds):\n",
    "    \"\"\"\n",
    "    Validates the trained machine learning model using precision, recall, and F1.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    y : np.array\n",
    "        Known labels, binarized.\n",
    "    preds : np.array\n",
    "        Predicted labels, binarized.\n",
    "    Returns\n",
    "    -------\n",
    "    precision : float\n",
    "    recall : float\n",
    "    fbeta : float\n",
    "    \"\"\"\n",
    "    fbeta = fbeta_score(y, preds, beta=1, zero_division=1)\n",
    "    precision = precision_score(y, preds, zero_division=1)\n",
    "    recall = recall_score(y, preds, zero_division=1)\n",
    "    return precision, recall, fbeta\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving Trained Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "### Assuming you have a trained model named 'model'\n",
    "### Save the model to a file\n",
    "### dump(model, './../model/model.joblib')\n",
    "def save_trained_model(trained_model_clf, path_to_save: str):\n",
    "    dump(trained_model_clf, path_to_save)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Executing all steps together:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajmohammad/opt/anaconda3/envs/udacity/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, precision_score, recall_score\n",
    "\n",
    "data = pd.read_csv(\"testdataset_unittest.csv\")\n",
    "\n",
    "# Droping duplicate rows\n",
    "data.drop_duplicates(inplace=True)\n",
    "# Removing 2 unneeded columns\n",
    "data.drop(['capital-gain', 'capital-loss'], axis=1, inplace=True)\n",
    "# Optional enhancement, use K-fold cross validation instead of a train-test split.\n",
    "train, test = train_test_split(data, test_size=0.20)\n",
    "#expected_train_or_test_shape = 13\n",
    "#assert train.shape[1] == expected_train_or_test_shape\n",
    "#assert test.shape[1] == expected_train_or_test_shape\n",
    "\n",
    "# Proces the test data with the process_data function.\n",
    "cat_features = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "]\n",
    "\n",
    "X_train, y_train, encoder, lb = process_data(\n",
    "    train, categorical_features=cat_features, label=\"salary\", training=True)\n",
    "    \n",
    "\n",
    "\n",
    "training = train_model(X_train=X_train, y_train=y_train)\n",
    "\n",
    "# Testing inference from model code\n",
    "X_test, y_test, _, _ = process_data(\n",
    "    test, categorical_features=cat_features, label=\"salary\", training=False, encoder=encoder, lb=lb)\n",
    "y_pred = inference(training, X_test)\n",
    "expected_pred = [0, 0]\n",
    "\n",
    "\n",
    "# Testing compute_model_metrics from model code\n",
    "fbeta, precision, recall = compute_model_metrics(y_test, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performance of the model on slices of the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for slices of 'workclass':\n",
      " - Slice value 'Private': 1.0\n",
      " - Slice value 'Local-gov': 1.0\n",
      " - Slice value 'Federal-gov': 1.0\n",
      " - Slice value 'Self-emp-not-inc': 1.0\n",
      " - Slice value 'State-gov': 1.0\n",
      " - Slice value 'Self-emp-inc': 1.0\n",
      " - Slice value '?': 1.0\n",
      "Performance for slices of 'education':\n",
      " - Slice value 'Some-college': 1.0\n",
      " - Slice value 'Bachelors': 1.0\n",
      " - Slice value 'HS-grad': 1.0\n",
      " - Slice value '9th': 1.0\n",
      " - Slice value '12th': 1.0\n",
      " - Slice value '10th': 1.0\n",
      " - Slice value '7th-8th': 1.0\n",
      " - Slice value 'Assoc-voc': 1.0\n",
      " - Slice value 'Prof-school': 1.0\n",
      " - Slice value 'Assoc-acdm': 1.0\n",
      " - Slice value 'Masters': 1.0\n",
      " - Slice value '11th': 1.0\n",
      "Performance for slices of 'marital-status':\n",
      " - Slice value 'Never-married': 1.0\n",
      " - Slice value 'Married-civ-spouse': 1.0\n",
      " - Slice value 'Married-spouse-absent': 1.0\n",
      " - Slice value 'Divorced': 1.0\n",
      " - Slice value 'Separated': 1.0\n",
      " - Slice value 'Widowed': 1.0\n",
      "Performance for slices of 'occupation':\n",
      " - Slice value 'Sales': 1.0\n",
      " - Slice value 'Adm-clerical': 1.0\n",
      " - Slice value 'Tech-support': 1.0\n",
      " - Slice value 'Transport-moving': 1.0\n",
      " - Slice value 'Prof-specialty': 1.0\n",
      " - Slice value 'Machine-op-inspct': 1.0\n",
      " - Slice value 'Other-service': 1.0\n",
      " - Slice value 'Exec-managerial': 1.0\n",
      " - Slice value 'Craft-repair': 1.0\n",
      " - Slice value 'Handlers-cleaners': 1.0\n",
      " - Slice value 'Protective-serv': 1.0\n",
      " - Slice value '?': 1.0\n",
      " - Slice value 'Farming-fishing': 1.0\n",
      "Performance for slices of 'relationship':\n",
      " - Slice value 'Own-child': 1.0\n",
      " - Slice value 'Wife': 1.0\n",
      " - Slice value 'Husband': 1.0\n",
      " - Slice value 'Not-in-family': 1.0\n",
      " - Slice value 'Unmarried': 1.0\n",
      " - Slice value 'Other-relative': 1.0\n",
      "Performance for slices of 'race':\n",
      " - Slice value 'White': 1.0\n",
      " - Slice value 'Black': 1.0\n",
      " - Slice value 'Other': 1.0\n",
      " - Slice value 'Asian-Pac-Islander': 1.0\n",
      " - Slice value 'Amer-Indian-Eskimo': 1.0\n",
      "Performance for slices of 'sex':\n",
      " - Slice value 'Male': 1.0\n",
      " - Slice value 'Female': 1.0\n",
      "Performance for slices of 'native-country':\n",
      " - Slice value 'United-States': 1.0\n",
      " - Slice value 'Peru': 1.0\n",
      " - Slice value 'Mexico': 1.0\n",
      " - Slice value 'Puerto-Rico': 1.0\n",
      " - Slice value 'England': 1.0\n"
     ]
    }
   ],
   "source": [
    "from model import train_model\n",
    "from model import inference\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def calculate_data_slice_performance(train_model, inference, data, slice_features, output_file=\"slice_output.txt\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the performance of a model on slices of categorical features.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model object that has a `predict` method.\n",
    "    - data: The input data as a pandas DataFrame.\n",
    "    - slice_features: A list of categorical features to slice on.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary mapping each categorical feature to its slice performance dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    slice_performance = {}\n",
    "\n",
    "    # Separate input features (X) and target variable (y)\n",
    "    X = data.drop(slice_features, axis=1)\n",
    "    y = data[slice_features]\n",
    "\n",
    "    # Perform one-hot encoding on the input features\n",
    "    ct = ColumnTransformer([('encoder', OneHotEncoder(), list(X.columns))], remainder='passthrough')\n",
    "    X_encoded = ct.fit_transform(X)\n",
    "\n",
    "    for feature in slice_features:\n",
    "        slice_performance[feature] = {}\n",
    "\n",
    "        # Get unique values of the current slice feature\n",
    "        slice_values = data[feature].unique()\n",
    "\n",
    "        for value in slice_values:\n",
    "            # Create a mask for the current slice value\n",
    "            mask = data[feature] == value\n",
    "\n",
    "            # Apply the mask to the data\n",
    "            sliced_data = data[mask]\n",
    "\n",
    "            # Separate input features (X_slice) and target variable (y_slice)\n",
    "            X_slice = sliced_data.drop(slice_features, axis=1)\n",
    "            y_slice = sliced_data[feature]\n",
    "\n",
    "            # Perform one-hot encoding on the sliced input features\n",
    "            X_slice_encoded = ct.transform(X_slice)\n",
    "\n",
    "            # Train the model\n",
    "            model = train_model(X_encoded, y[feature])\n",
    "\n",
    "            # Make predictions on the sliced data\n",
    "            y_pred = inference(model, X_slice_encoded)\n",
    "\n",
    "            # Calculate accuracy score for the slice\n",
    "            performance = accuracy_score(y_slice, y_pred)\n",
    "\n",
    "            # Store the performance in the dictionary\n",
    "            slice_performance[feature][value] = performance\n",
    "\n",
    "    # Print the performance for each slice combination\n",
    "    with open(output_file, 'w') as f:\n",
    "        for feature, performance_dict in slice_performance.items():\n",
    "            f.write(f\"Performance for slices of '{feature}':\\n\")\n",
    "            print(f\"Performance for slices of '{feature}':\")\n",
    "            for value, performance in performance_dict.items():\n",
    "                f.write(f\" - Slice value '{value}': {performance}\\n\")\n",
    "                print(f\" - Slice value '{value}': {performance}\")\n",
    "\n",
    "\n",
    "# Define the categorical features to slice on\n",
    "slice_features = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "\n",
    "# Calculate the performance on slices based on the categorical features\n",
    "calculate_data_slice_performance(train_model, inference, data, slice_features)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
